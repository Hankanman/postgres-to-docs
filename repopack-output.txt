This file is a merged representation of the entire codebase, combining all repository files into a single document.
Generated by Repopack on: 2024-09-11T14:51:33.332Z

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Repository structure
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repopack's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.

Additional Info:
----------------

For more information about Repopack, visit: https://github.com/yamadashy/repopack

================================================================
Repository Structure
================================================================
.github/CODE_OF_CONDUCT.md
.github/CONTRIBUTING.md
.github/SECURITY.md
.github/workflows/pr.yml
.github/workflows/push-master.yml
.github/workflows/repolint.yml
.gitignore
.prettierrc.json
CHANGELOG.md
docker-compose.yml
jest.config.js
LICENSE
package.json
README.md
src/arguments.spec.ts
src/arguments.ts
src/cli.ts
src/config.ts
src/database.integration.spec.ts
src/database.ts
src/file.ts
src/format.ts
src/get-schema.spec.ts
src/get-schema.ts
src/index.ts
src/postgre-data-types.json
src/repository.ts
tsconfig.json

================================================================
Repository Files
================================================================

================
File: .github/CODE_OF_CONDUCT.md
================
# Contributor Covenant Code of Conduct

## Our Pledge

We as members, contributors, and leaders pledge to make participation in our
community a harassment-free experience for everyone, regardless of age, body
size, visible or invisible disability, ethnicity, sex characteristics, gender
identity and expression, level of experience, education, socio-economic status,
nationality, personal appearance, race, religion, political beliefs, or sexual
identity and orientation.

We pledge to act and interact in ways that contribute to an open, welcoming,
diverse, inclusive, and healthy community.

## Our Standards

Examples of behavior that contributes to a positive environment for our
community include:

- Demonstrating empathy and kindness toward other people
- Being respectful of differing opinions, viewpoints, and experiences
- Giving and gracefully accepting constructive feedback
- Accepting responsibility and apologizing to those affected by our mistakes,
  and learning from the experience
- Focusing on what is best not just for us as individuals, but for the
  overall community

Examples of unacceptable behavior include:

- The use of sexualized language or imagery, and sexual attention or
  advances of any kind
- Trolling, insulting or derogatory comments, and personal or political attacks
- Public or private harassment
- Publishing others' private information, such as a physical or email
  address, without their explicit permission
- Other conduct which could reasonably be considered inappropriate in a
  professional setting

## Enforcement Responsibilities

Community leaders are responsible for clarifying and enforcing our standards of
acceptable behavior and will take appropriate and fair corrective action in
response to any behavior that they deem inappropriate, threatening, offensive,
or harmful.

Community leaders have the right and responsibility to remove, edit, or reject
comments, commits, code, wiki edits, issues, and other contributions that are
not aligned to this Code of Conduct, and will communicate reasons for moderation
decisions when appropriate.

## Scope

This Code of Conduct applies within all community spaces, and also applies when
an individual is officially representing the community in public spaces.
Examples of representing our community include using an official e-mail address,
posting via an official social media account, or acting as an appointed
representative at an online or offline event.

## Enforcement

Instances of abusive, harassing, or otherwise unacceptable behavior may be
reported to the community leaders responsible for enforcement at
developers@hankanman.com.
All complaints will be reviewed and investigated promptly and fairly.

All community leaders are obligated to respect the privacy and security of the
reporter of any incident.

## Enforcement Guidelines

Community leaders will follow these Community Impact Guidelines in determining
the consequences for any action they deem in violation of this Code of Conduct:

### 1. Correction

**Community Impact**: Use of inappropriate language or other behavior deemed
unprofessional or unwelcome in the community.

**Consequence**: A private, written warning from community leaders, providing
clarity around the nature of the violation and an explanation of why the
behavior was inappropriate. A public apology may be requested.

### 2. Warning

**Community Impact**: A violation through a single incident or series
of actions.

**Consequence**: A warning with consequences for continued behavior. No
interaction with the people involved, including unsolicited interaction with
those enforcing the Code of Conduct, for a specified period of time. This
includes avoiding interactions in community spaces as well as external channels
like social media. Violating these terms may lead to a temporary or
permanent ban.

### 3. Temporary Ban

**Community Impact**: A serious violation of community standards, including
sustained inappropriate behavior.

**Consequence**: A temporary ban from any sort of interaction or public
communication with the community for a specified period of time. No public or
private interaction with the people involved, including unsolicited interaction
with those enforcing the Code of Conduct, is allowed during this period.
Violating these terms may lead to a permanent ban.

### 4. Permanent Ban

**Community Impact**: Demonstrating a pattern of violation of community
standards, including sustained inappropriate behavior, harassment of an
individual, or aggression toward or disparagement of classes of individuals.

**Consequence**: A permanent ban from any sort of public interaction within
the community.

## Attribution

This Code of Conduct is adapted from the [Contributor Covenant][homepage],
version 2.0, available at
https://www.contributor-covenant.org/version/2/0/code_of_conduct.html.

Community Impact Guidelines were inspired by [Mozilla's code of conduct
enforcement ladder](https://github.com/mozilla/diversity).

[homepage]: https://www.contributor-covenant.org

For answers to common questions about this code of conduct, see the FAQ at
https://www.contributor-covenant.org/faq. Translations are available at
https://www.contributor-covenant.org/translations.

================
File: .github/CONTRIBUTING.md
================
# Contributing to this Klarna project

Are you here to help with this Klarna project? Welcome! Please read the following to better understand how to ask questions or work on something.

All members of our community are expected to follow our [Code of Conduct](CODE_OF_CONDUCT.md). Please make sure you are welcoming and friendly in all of our spaces.

## Get in touch

- Report bugs, suggest features or view the source code on GitHub.
- If you have any questions concerning this product, please contact developers@hankanman.com.

## Contributing to development

At Klarna, we strive toward achieving the highest possible quality for our
products. Therefore, we require you to follow these guidelines if you wish
to contribute.

Your contribution has to meet the following criteria:

- It is accompanied by a description regarding what has been changed and why.
- Pull requests should implement a boxed change, meaning they should optimally not try to address many things at once.
- All code and documentation must follow the style specified by
  the included configuration.
- New features and bug fixes must have accompanying unit tests.
- All unit tests should pass.

================
File: .github/SECURITY.md
================
# Security Guidelines for this Project

## How the Klarna Security team manages security for this project

Klarna takes security seriously and wants to ensure that we maintain a secure environment for our customers and that we also provide secure solutions for the open source community. To help us achieve these goals, please note the following before using this software:

  - Review the software license to understand Klarna's obligations in terms of warranties and suitability for purpose
  - For any questions or concerns about security, you can reach out directly to Klarna's security team at security@hankanman.com 
  - We request that you work with our security team and opt for [responsible disclosure](https://corporate.walmart.com/article/responsible-disclosure-policy) using the guidelines below
  - We enforce SLAs on our security team and software engineers to remediate security bugs in a timely manner
  - All security related issues and pull requests you make should be tagged with "security" for easy identification
  - Please monitor this repository and update your environment in a timely manner as we release patches and updates

## Responsibly Disclosing Security Bugs to Klarna

If you find a security bug in this repository, please work with Klarna's security team following responsible disclosure principles and these guidelines: 

  - Do not submit a normal issue or pull request in our public repository, instead report directly to security@hankanman.com (If you would like to encrypt, please contact us for keys)
  - We will review your submission and may follow up for additional details
  - If you have a patch, we will review it and approve it privately; once approved for release you can submit it as a pull request publicly in our repos (we give credit where credit is due)
  - We will keep you informed during our investigation, feel free to check in for a status update
  - We will release the fix and publicly disclose the issue as soon as possible, but want  to ensure we due properly due diligence before releasing 
  - Please do not publicly blog or post about the security issue until after we have updated the public repo so that other downstream users have an opportunity to patch

## Contact / Misc.

If you have any questions, please reach out directly to the Klarna Security team at security@hankanman.com

================
File: .github/workflows/pr.yml
================
name: Pull request

on:
  pull_request:
    branches: [master]

jobs:
  publish:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v1
      - uses: actions/setup-node@v1
        with:
          node-version: 12
      - run: npm install
      - run: npm test
      - run: npm run build

================
File: .github/workflows/push-master.yml
================
name: Push master

on:
  push:
    branches: [master]

jobs:
  publish:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v1
      - uses: actions/setup-node@v1
        with:
          node-version: 12
      - run: npm install
      - run: npm test
      - run: npm run build
      - id: publish
        uses: JS-DevTools/npm-publish@v1
        with:
          token: ${{ secrets.NPM_TOKEN }}
          access: public
      - if: steps.publish.outputs.type != 'none'
        run: |
          echo "Version changed: ${{ steps.publish.outputs.old-version }} => ${{ steps.publish.outputs.version }}"

================
File: .github/workflows/repolint.yml
================
name: Klarna repolint

on:
  push:
    branches: [master]
  pull_request:
    branches: [master]

jobs:
  lint:
    runs-on: ubuntu-latest

    steps:
      # Checks-out the repository under $GITHUB_WORKSPACE
      - uses: actions/checkout@v2

      - name: Install dependencies
        run: npm install repolinter log-symbols

      # @TODO Remove when fixed
      - name: Fix missing dependency in repolint
        run: npm install is-windows

      - name: Use custom rules
        run: wget https://raw.githubusercontent.com/Hankanman/meta/master/repolint.json

      - name: Run repolint
        run: ./node_modules/.bin/repolinter $GITHUB_WORKSPACE

================
File: .gitignore
================
.DS_Store
node_modules
dist

================
File: .prettierrc.json
================
{
  "semi": false,
  "singleQuote": true
}

================
File: CHANGELOG.md
================
# Changelog

All notable changes to this project will be documented in this file.

The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/),
and this project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).

## [Unreleased] - yyyy-mm-dd

## [0.1.1] - 2020-03-15

### Added

- Initial release

<!-- Markdown link dfn's -->
[unreleased]: https://github.com/Hankanman/postgres-to-docs/compare/v0.1.1...HEAD
[0.1.1]: https://github.com/Hankanman/postgres-to-docs/releases/tag/v0.1.1

================
File: docker-compose.yml
================
version: '3'
services:
  postgres:
    image: postgres
    ports:
      - '5432:5432'
    environment:
      POSTGRES_USER: postgres-to-docs
      POSTGRES_PASSWORD: postgres-to-docs
      POSTGRES_DB: postgres-to-docs

================
File: jest.config.js
================
module.exports = {
  preset: 'ts-jest',
  testEnvironment: 'node',
};

================
File: LICENSE
================
Apache License
                           Version 2.0, January 2004
                        http://www.apache.org/licenses/

   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION

   1. Definitions.

      "License" shall mean the terms and conditions for use, reproduction,
      and distribution as defined by Sections 1 through 9 of this document.

      "Licensor" shall mean the copyright owner or entity authorized by
      the copyright owner that is granting the License.

      "Legal Entity" shall mean the union of the acting entity and all
      other entities that control, are controlled by, or are under common
      control with that entity. For the purposes of this definition,
      "control" means (i) the power, direct or indirect, to cause the
      direction or management of such entity, whether by contract or
      otherwise, or (ii) ownership of fifty percent (50%) or more of the
      outstanding shares, or (iii) beneficial ownership of such entity.

      "You" (or "Your") shall mean an individual or Legal Entity
      exercising permissions granted by this License.

      "Source" form shall mean the preferred form for making modifications,
      including but not limited to software source code, documentation
      source, and configuration files.

      "Object" form shall mean any form resulting from mechanical
      transformation or translation of a Source form, including but
      not limited to compiled object code, generated documentation,
      and conversions to other media types.

      "Work" shall mean the work of authorship, whether in Source or
      Object form, made available under the License, as indicated by a
      copyright notice that is included in or attached to the work
      (an example is provided in the Appendix below).

      "Derivative Works" shall mean any work, whether in Source or Object
      form, that is based on (or derived from) the Work and for which the
      editorial revisions, annotations, elaborations, or other modifications
      represent, as a whole, an original work of authorship. For the purposes
      of this License, Derivative Works shall not include works that remain
      separable from, or merely link (or bind by name) to the interfaces of,
      the Work and Derivative Works thereof.

      "Contribution" shall mean any work of authorship, including
      the original version of the Work and any modifications or additions
      to that Work or Derivative Works thereof, that is intentionally
      submitted to Licensor for inclusion in the Work by the copyright owner
      or by an individual or Legal Entity authorized to submit on behalf of
      the copyright owner. For the purposes of this definition, "submitted"
      means any form of electronic, verbal, or written communication sent
      to the Licensor or its representatives, including but not limited to
      communication on electronic mailing lists, source code control systems,
      and issue tracking systems that are managed by, or on behalf of, the
      Licensor for the purpose of discussing and improving the Work, but
      excluding communication that is conspicuously marked or otherwise
      designated in writing by the copyright owner as "Not a Contribution."

      "Contributor" shall mean Licensor and any individual or Legal Entity
      on behalf of whom a Contribution has been received by Licensor and
      subsequently incorporated within the Work.

   2. Grant of Copyright License. Subject to the terms and conditions of
      this License, each Contributor hereby grants to You a perpetual,
      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
      copyright license to reproduce, prepare Derivative Works of,
      publicly display, publicly perform, sublicense, and distribute the
      Work and such Derivative Works in Source or Object form.

   3. Grant of Patent License. Subject to the terms and conditions of
      this License, each Contributor hereby grants to You a perpetual,
      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
      (except as stated in this section) patent license to make, have made,
      use, offer to sell, sell, import, and otherwise transfer the Work,
      where such license applies only to those patent claims licensable
      by such Contributor that are necessarily infringed by their
      Contribution(s) alone or by combination of their Contribution(s)
      with the Work to which such Contribution(s) was submitted. If You
      institute patent litigation against any entity (including a
      cross-claim or counterclaim in a lawsuit) alleging that the Work
      or a Contribution incorporated within the Work constitutes direct
      or contributory patent infringement, then any patent licenses
      granted to You under this License for that Work shall terminate
      as of the date such litigation is filed.

   4. Redistribution. You may reproduce and distribute copies of the
      Work or Derivative Works thereof in any medium, with or without
      modifications, and in Source or Object form, provided that You
      meet the following conditions:

      (a) You must give any other recipients of the Work or
          Derivative Works a copy of this License; and

      (b) You must cause any modified files to carry prominent notices
          stating that You changed the files; and

      (c) You must retain, in the Source form of any Derivative Works
          that You distribute, all copyright, patent, trademark, and
          attribution notices from the Source form of the Work,
          excluding those notices that do not pertain to any part of
          the Derivative Works; and

      (d) If the Work includes a "NOTICE" text file as part of its
          distribution, then any Derivative Works that You distribute must
          include a readable copy of the attribution notices contained
          within such NOTICE file, excluding those notices that do not
          pertain to any part of the Derivative Works, in at least one
          of the following places: within a NOTICE text file distributed
          as part of the Derivative Works; within the Source form or
          documentation, if provided along with the Derivative Works; or,
          within a display generated by the Derivative Works, if and
          wherever such third-party notices normally appear. The contents
          of the NOTICE file are for informational purposes only and
          do not modify the License. You may add Your own attribution
          notices within Derivative Works that You distribute, alongside
          or as an addendum to the NOTICE text from the Work, provided
          that such additional attribution notices cannot be construed
          as modifying the License.

      You may add Your own copyright statement to Your modifications and
      may provide additional or different license terms and conditions
      for use, reproduction, or distribution of Your modifications, or
      for any such Derivative Works as a whole, provided Your use,
      reproduction, and distribution of the Work otherwise complies with
      the conditions stated in this License.

   5. Submission of Contributions. Unless You explicitly state otherwise,
      any Contribution intentionally submitted for inclusion in the Work
      by You to the Licensor shall be under the terms and conditions of
      this License, without any additional terms or conditions.
      Notwithstanding the above, nothing herein shall supersede or modify
      the terms of any separate license agreement you may have executed
      with Licensor regarding such Contributions.

   6. Trademarks. This License does not grant permission to use the trade
      names, trademarks, service marks, or product names of the Licensor,
      except as required for reasonable and customary use in describing the
      origin of the Work and reproducing the content of the NOTICE file.

   7. Disclaimer of Warranty. Unless required by applicable law or
      agreed to in writing, Licensor provides the Work (and each
      Contributor provides its Contributions) on an "AS IS" BASIS,
      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
      implied, including, without limitation, any warranties or conditions
      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
      PARTICULAR PURPOSE. You are solely responsible for determining the
      appropriateness of using or redistributing the Work and assume any
      risks associated with Your exercise of permissions under this License.

   8. Limitation of Liability. In no event and under no legal theory,
      whether in tort (including negligence), contract, or otherwise,
      unless required by applicable law (such as deliberate and grossly
      negligent acts) or agreed to in writing, shall any Contributor be
      liable to You for damages, including any direct, indirect, special,
      incidental, or consequential damages of any character arising as a
      result of this License or out of the use or inability to use the
      Work (including but not limited to damages for loss of goodwill,
      work stoppage, computer failure or malfunction, or any and all
      other commercial damages or losses), even if such Contributor
      has been advised of the possibility of such damages.

   9. Accepting Warranty or Additional Liability. While redistributing
      the Work or Derivative Works thereof, You may choose to offer,
      and charge a fee for, acceptance of support, warranty, indemnity,
      or other liability obligations and/or rights consistent with this
      License. However, in accepting such obligations, You may act only
      on Your own behalf and on Your sole responsibility, not on behalf
      of any other Contributor, and only if You agree to indemnify,
      defend, and hold each Contributor harmless for any liability
      incurred by, or claims asserted against, such Contributor by reason
      of your accepting any such warranty or additional liability.

   END OF TERMS AND CONDITIONS

   APPENDIX: How to apply the Apache License to your work.

      To apply the Apache License to your work, attach the following
      boilerplate notice, with the fields enclosed by brackets "[]"
      replaced with your own identifying information. (Don't include
      the brackets!)  The text should be enclosed in the appropriate
      comment syntax for the file format. We also recommend that a
      file or class name and description of purpose be included on the
      same "printed page" as the copyright notice for easier
      identification within third-party archives.

   Copyright [yyyy] [name of copyright owner]

   Licensed under the Apache License, Version 2.0 (the "License");
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.

================
File: package.json
================
{
  "name": "@hankanman/postgres-to-docs",
  "version": "0.1.2",
  "description": "The smoooth way to document your Postgres database",
  "main": "./dist/index.js",
  "bin": "./dist/cli.js",
  "prepublish": "tsc -p ./tsconfig.json",
  "scripts": {
    "test": "docker-compose up -d && sleep 5 && jest ./src --passWithNoTests && docker-compose down",
    "start:dev": "ts-node ./src/cli.ts",
    "build": "tsc -p ./tsconfig.json"
  },
  "repository": {
    "type": "git",
    "url": "git+https://github.com/Hankanman/postgres-to-docs.git"
  },
  "author": "",
  "license": "Apache-2.0",
  "bugs": {
    "url": "https://github.com/Hankanman/postgres-to-docs/issues"
  },
  "homepage": "https://github.com/Hankanman/postgres-to-docs#readme",
  "dependencies": {
    "elm-decoders": "^6.0.1",
    "pg": "^8.5.1",
    "json2md": "^1.10.0"
  },
  "devDependencies": {
    "@types/jest": "^26.0.21",
    "@types/json2md": "^1.5.0",
    "@types/pg": "^7.14.11",
    "jest": "^26.6.3",
    "ts-jest": "^26.5.4",
    "ts-node": "^9.1.1",
    "typescript": "^4.2.3"
  }
}

================
File: README.md
================
# postgres-to-docs
[![Build Status][ci-image]][ci-url]
[![License][license-image]][license-url]
[![Developed at Klarna][klarna-image]][klarna-url]

Make your database documentation smoooth by generating markdown for your schema.

## Usage

1.  Install through npm
```
npm install @hankanman/postgres-to-docs
```

2. Define a `json` config file
```
{
    "host": "localhost",
    "port": 5432,
    "user": "user",
    "password": "password",
    "database": "database"
}
```
3. Run the tool
```
postgres-to-docs --config=config.json --output=schema.md
```
Where `--config` is the path to your config file and `--output`is the path to the output markdown file


## Problem
You need to get a quick and easy overview of your database schema but don't want to...
* Open the source code and find the model definitions
* Start your database and service, install dependencies, have a proper configuration, and open an external tool like TablePlus or DBeaver
* Read through your migrations directory to find the latest version of your schema
* Look through external documentation that might be out of date


## Introducing postgres-to-docs!
A Node CLI that renders your schemas as markdown and keeps it up to date! Generates documentation for
- [X] Tables - PKs, FKs, Nullable and Default values
- [X] Views
- [X] User defined types like composites and enums

## Future work
- [ ] Additional export formats like entity relationship-diagrams
- [ ] Materialized views
- [ ] Support for watch-mode to rerun the tool on file change


## Development
Clone the repo, then:

```
npm install
npm run start:dev
```

## How to contribute

See our guide on [contributing](.github/CONTRIBUTING.md).

## Release History

See our [changelog](CHANGELOG.md).

## License

Copyright © 2021 Klarna Bank AB

For license details, see the [LICENSE](LICENSE) file in the root of this project.


<!-- Markdown link & img dfn's -->
[ci-image]: https://img.shields.io/badge/build-passing-brightgreen?style=flat-square
[ci-url]: https://github.com/Hankanman/TODO
[license-image]: https://img.shields.io/badge/license-Apache%202-blue?style=flat-square
[license-url]: http://www.apache.org/licenses/LICENSE-2.0
[klarna-image]: https://img.shields.io/badge/%20-Developed%20at%20Klarna-black?labelColor=ffb3c7&style=flat-square&logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAOCAYAAAAmL5yKAAAAAXNSR0IArs4c6QAAAIRlWElmTU0AKgAAAAgABQESAAMAAAABAAEAAAEaAAUAAAABAAAASgEbAAUAAAABAAAAUgEoAAMAAAABAAIAAIdpAAQAAAABAAAAWgAAAAAAAALQAAAAAQAAAtAAAAABAAOgAQADAAAAAQABAACgAgAEAAAAAQAAABCgAwAEAAAAAQAAAA4AAAAA0LMKiwAAAAlwSFlzAABuugAAbroB1t6xFwAAAVlpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IlhNUCBDb3JlIDUuNC4wIj4KICAgPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4KICAgICAgPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIKICAgICAgICAgICAgeG1sbnM6dGlmZj0iaHR0cDovL25zLmFkb2JlLmNvbS90aWZmLzEuMC8iPgogICAgICAgICA8dGlmZjpPcmllbnRhdGlvbj4xPC90aWZmOk9yaWVudGF0aW9uPgogICAgICA8L3JkZjpEZXNjcmlwdGlvbj4KICAgPC9yZGY6UkRGPgo8L3g6eG1wbWV0YT4KTMInWQAAAVBJREFUKBVtkz0vREEUhsdXgo5qJXohkUgQ0fgFNFpR2V5ClP6CQu9PiB6lEL1I7B9A4/treZ47c252s97k2ffMmZkz5869m1JKL/AFbzAHaiRbmsIf4BdaMAZqMFsOXNxXkroKbxCPV5l8yHOJLVipn9/vEreLa7FguSN3S2ynA/ATeQuI8tTY6OOY34DQaQnq9mPCDtxoBwuRxPfAvPMWnARlB12KAi6eLTPruOOP4gcl33O6+Sjgc83DJkRH+h2MgorLzaPy68W48BG2S+xYnmAa1L+nOxEduMH3fgjGFvZeVkANZau68B6CrgJxWosFFpF7iG+h5wKZqwt42qIJtARu/ix+gqsosEq8D35o6R3c7OL4lAnTDljEe9B3Qa2BYzmHemDCt6Diwo6JY7E+A82OnN9HuoBruAQvUQ1nSxP4GVzBDRyBfygf6RW2/gD3NmEv+K/DZgAAAABJRU5ErkJggg==
[klarna-url]: https://github.com/Hankanman

================
File: src/arguments.spec.ts
================
import { parseArguments } from './arguments'

describe('arguments', () => {
  it('can parse CLI arguments to an object', () => {
    const args = ['', '', '--config=something']
    expect(parseArguments(args)).toEqual({ config: 'something' })
  })

  it('gracefully handles no arguments', () => {
    const args = ['', '']
    expect(parseArguments(args)).toEqual({})
  })
})

================
File: src/arguments.ts
================
export const parseArguments = (argv: string[]) => {
  const [_, __, ...args] = argv
  return args
    .map((arg) => {
      if (!arg.startsWith('--')) return {}
      const [flag, value] = arg.split('=')
      const withoutDashes = flag.slice(2)
      return { [withoutDashes]: value }
    })
    .reduce((acc, next) => ({ ...acc, ...next }), {})
}

================
File: src/cli.ts
================
#!/usr/bin/env node

import { generateDocumentation } from '.'
import { parseArguments } from './arguments'

const run = async () => {
  const rawArguments = parseArguments(process.argv)
  if (!rawArguments.config || !rawArguments.output) {
    console.log('failed, "--config" and "--output" required')
    process.exit(1)
  }

  try {
    await generateDocumentation(rawArguments.config, rawArguments.output)
  } catch (e) {
    console.log('Failed', e)
    process.exit(1)
  }
}

run()

================
File: src/config.ts
================
import { Decoder } from 'elm-decoders'

export type Config = {
  host: string
  user: string
  password: string
  database: string
  port: number
}

const configDecoder = Decoder.object({
  host: Decoder.string,
  user: Decoder.string,
  password: Decoder.string,
  database: Decoder.string,
  port: Decoder.number
})

export const parseConfig = (environment: any): Config =>
  configDecoder.guard(environment)

================
File: src/database.integration.spec.ts
================
import { Config } from './config'
import { createDatabase, Database } from './database'

describe('database', () => {
  const config: Config = {
    host: 'localhost',
    port: 5432,
    user: 'postgres-to-docs',
    password: 'postgres-to-docs',
    database: 'postgres-to-docs',
  }

  let database: Database
  beforeAll(async () => {
    database = await createDatabase(config)
  })

  afterAll(async () => {
    await database.disconnect()
  })

  it('can connect', async () => {
    const isAlive = await database.isAlive()
    expect(isAlive).toBe(true)
  })

  it('can query', async () => {
    const res = await database.query('SELECT 1')
    expect(res).toBeDefined()
  })
})

================
File: src/database.ts
================
import { Pool } from 'pg'
import { Config } from './config'

export type Database = {
  isAlive: () => Promise<boolean>
  disconnect: () => Promise<void>
  query: (queryString: string, args?: any[]) => Promise<any>
}

export const createDatabase = async (config: Config): Promise<Database> => {
  const pool = new Pool({
    user: config.user,
    host: config.host,
    database: config.database,
    password: config.password,
    port: config.port,
  })

  try {
    await pool.query('SELECT 1')
  } catch (e) {
    throw new Error(`Failed to connect to DB ${e}`)
  }

  const isAlive = async () => {
    try {
      await pool.query('SELECT 1')
      return true
    } catch (e) {
      return false
    }
  }

  const query = async (queryString: string, args?: any[]): Promise<unknown> => {
    const client = await pool.connect()
    try {
      const result = await client.query(queryString, args)
      client.release()
      return result
    } catch (e) {
      client.release()
      throw e
    }
  }

  const disconnect = async () => {
    await pool.end()
  }

  return {
    isAlive,
    disconnect,
    query,
  }
}

================
File: src/file.ts
================
import fs from 'fs'

export const read = (path: string) =>
  new Promise((resolve, reject) => {
    fs.readFile(path, (err, res) => {
      if (err) {
        reject(err)
        return
      }
      resolve(JSON.parse(res.toString()))
    })
  })

export const write = (path: string, content: string) =>
  new Promise((resolve, reject) => {
    fs.writeFile(path, content, (err) => {
      if (err) {
        reject(err)
        return
      }
      resolve(null)
    })
  })

================
File: src/format.ts
================
import {
  ColumnDescription,
  Schema,
  TableDescription,
  CompositeTypeDescription,
} from './get-schema'
import { CustomType } from './repository'
import json2md from 'json2md'
import typeDocumentation from './postgre-data-types.json'

const TYPES = typeDocumentation as any

export const format = (schema: Schema) => {
  const customTypeNames = schema.customTypes.map((t) => t.name)
  const compositeTypeNames = schema.compositeTypes.map((t) => t.name)
  const typeNames = new Set(customTypeNames.concat(compositeTypeNames))
  return json2md(
    [
      generateTableSection(schema.tables, typeNames),
      generateViewsSection(schema.views, typeNames),
      generateTypesSection(
        schema.customTypes,
        schema.compositeTypes,
        typeNames
      ),
    ].flat()
  )
}

const generateTableSection = (
  tables: TableDescription[],
  typeNames: Set<string>
) => {
  if (tables.length === 0) {
    return []
  }

  return [{ h1: 'Tables' }, generateTablesMarkdown(tables, typeNames)]
}

const generateViewsSection = (
  views: TableDescription[],
  typeNames: Set<string>
) => {
  if (views.length === 0) {
    return []
  }

  return [{ h1: 'Views' }, generateTablesMarkdown(views, typeNames)]
}

const generateTypesSection = (
  customTypes: CustomType[],
  compositeTypes: CompositeTypeDescription[],
  typeNames: Set<string>
) => {
  if (customTypes.length === 0 && compositeTypes.length === 0) {
    return []
  }

  return [
    { h1: 'Types' },
    generateTypesMarkdown(customTypes, compositeTypes, typeNames),
  ]
}

const generateTablesMarkdown = (
  tables: TableDescription[],
  typeNames: Set<string>
) => tables.map((t) => generateTableDescription(t, typeNames))

const generateTypesMarkdown = (
  customTypes: CustomType[],
  compositeTypes: CompositeTypeDescription[],
  typeNames: Set<string>
) =>
  [
    generateCustomTypesMarkdown(customTypes),
    generateCompositeTypesMarkdown(compositeTypes, typeNames),
  ].flat()

const generateCustomTypesMarkdown = (
  customTypes: CustomType[],
) => {
  return customTypes
    .map((custom) => generateCustomTypeMarkdown(custom))
    .flat()
}

const generateCustomTypeMarkdown = (
  custom: CustomType
) => {
  let nameWithAnchor = '<a name="' + custom.name + '" > </a>' + custom.name
  return [
    { h3: nameWithAnchor },
    { ul: custom.elements.map((elem) => elem.trim()) },
  ]
}

const generateCompositeTypesMarkdown = (
  compositeTypes: CompositeTypeDescription[],
  customTypeNames: Set<string>
) => {
  return compositeTypes
    .map((composite) =>
      generateCompositeTypeMarkdown(composite, customTypeNames)
    )
    .flat()
}

const generateCompositeTypeMarkdown = (
  composite: CompositeTypeDescription,
  customTypeNames: Set<string>
) => {
  const headers = ['column name', 'type', 'position', 'required?']
  let nameWithAnchor =
    '<a name="' + composite.name + '" > </a>' + composite.name
  let rows = composite.fields.map((field) => {
    const typeWithLink = maybeCreateTypeLink(field.dataType, customTypeNames)
    return [
      field.name,
      typeWithLink,
      field.position,
      field.isRequired.toString(),
    ]
  })
  return [
    { h3: nameWithAnchor },
    {
      table: {
        headers: headers,
        rows: rows,
      },
    },
  ]
}

const maybeCreateTypeLink = (type: string, customTypeNames: Set<string>) => {
  if (customTypeNames.has(type)) return `[${type}](#${type})`
  const docsUrl = type.match(/character \(\d+\)/) ? TYPES['character'] : TYPES[type]
  if (docsUrl) return `<a href="${docsUrl}">${type}</a>`
  return type
}

const generateTableDescription = (
  tableDescription: TableDescription,
  typeNames: Set<string>
) => {
  const nameWithAnchor = `<a name="${tableDescription.name}"></a>${tableDescription.name}`
  return [
    { h3: nameWithAnchor },
    generateMarkdownTable(tableDescription.columns, typeNames),
  ]
}

const generateMarkdownTable = (
  columns: ColumnDescription[],
  typeNames: Set<string>
) => {
  const headers = ['Name', 'Type', 'Default', 'Nullable', 'References']
  const rows = columns.map((column) => [
    formatColumnName(column.name, column.isPrimaryKey),
    formatDataType(column.dataType, typeNames),
    formatDefault(column.default),
    formatIsNullable(column.isNullable),
    formatForeignKey(column.foreignKey),
  ])

  return {
    table: {
      aligns: 'left',
      headers: headers,
      rows: rows,
    },
  }
}

const formatColumnName = (name: string, isPrimaryKey: boolean) =>
  isPrimaryKey
    ? `${name} <span style="background: #ddd; padding: 2px; font-size: 0.75rem; color: black">PK</span>`
    : name

const formatDataType = (type: string, typeNames: Set<string>) =>
  maybeCreateTypeLink(type, typeNames)

const formatDefault = (def?: string) => def || ''

const formatIsNullable = (isNullable: boolean) =>
  isNullable ? 'True' : 'False'

const formatForeignKey = (foreignKey?: string) =>
  foreignKey ? formatForeignKeyLink(foreignKey) : ''

const formatForeignKeyLink = (foreignKey: string) => {
  const otherTable = foreignKey.split('.')[0]
  return `[${foreignKey}](#${otherTable})`
}

================
File: src/get-schema.spec.ts
================
import { CompositeTypeDescription, getSchema } from './get-schema'
import {
  Column,
  CompositeType,
  CustomType,
  ForeignKey,
  PrimaryKey,
  Repository,
  Table,
} from './repository'

const emptyRepository = {
  selectTables: jest.fn().mockResolvedValue([]),
  selectColumns: jest.fn().mockResolvedValue([]),
  selectViews: jest.fn().mockResolvedValue([]),
  selectForeignKeys: jest.fn().mockResolvedValue([]),
  selectPrimaryKeys: jest.fn().mockResolvedValue([]),
  selectCustomTypes: jest.fn().mockResolvedValue([]),
  selectCompositeTypes: jest.fn().mockResolvedValue([]),
}

describe('Get schema', () => {
  it('returns empty results if no tables are available', async () => {
    const repository: Repository = {
      ...emptyRepository,
    }

    const schema = await getSchema(repository)
    expect(schema.tables.length).toBe(0)
    expect(schema.customTypes.length).toBe(0)
    expect(schema.compositeTypes.length).toBe(0)
    expect(schema.views.length).toBe(0)
  })

  it('returns columns grouped by table', async () => {
    const mockTableName = 'table'
    const mockTables: Table[] = [
      {
        name: mockTableName,
      },
    ]

    const mockColumns: Column[] = [
      {
        table: mockTableName,
        name: 'column_1',
        isNullable: true,
        dataType: 'int',
      },
      {
        table: mockTableName,
        name: 'column_2',
        isNullable: true,
        dataType: 'int',
      },
    ]
    const repository: Repository = {
      ...emptyRepository,
      selectTables: jest.fn().mockResolvedValue(mockTables),
      selectColumns: jest.fn().mockResolvedValue(mockColumns),
    }

    const schema = await getSchema(repository)
    expect(schema.tables.length).toBe(1)
    const schemaTable = schema.tables[0]

    expect(schemaTable.name).toBe(mockTableName)
    expect(schemaTable.columns.length).toBe(mockColumns.length)

    schemaTable.columns.forEach((c, index) => {
      expect(c.name).toBe(mockColumns[index].name)
    })
  })

  it('sets foreign keys and primary keys by table and column name', async () => {
    const mockTableName = 'table'
    const mockForeignTableName = 'foreign_table'
    const mockSourceColumn = 'column'
    const mockForeignColumn = 'foreign_column'

    const mockTables: Table[] = [
      {
        name: mockTableName,
      },
      { name: mockForeignTableName },
    ]

    const mockColumns: Column[] = [
      {
        table: mockTableName,
        name: mockSourceColumn,
        isNullable: true,
        dataType: 'int',
      },
      {
        table: mockForeignTableName,
        name: mockForeignColumn,
        isNullable: true,
        dataType: 'int',
      },
    ]

    const mockFKs: ForeignKey[] = [
      {
        constraintName: '',
        sourceTable: mockTableName,
        sourceColumn: mockSourceColumn,
        foreignTable: mockForeignTableName,
        foreignColumn: mockForeignColumn,
      },
    ]

    const mockPKs: PrimaryKey[] = [
      {
        constraintName: '',
        table: mockForeignTableName,
        column: mockForeignColumn,
      },
    ]
    const repository: Repository = {
      ...emptyRepository,
      selectTables: jest.fn().mockResolvedValue(mockTables),
      selectColumns: jest.fn().mockResolvedValue(mockColumns),
      selectForeignKeys: jest.fn().mockResolvedValue(mockFKs),
      selectPrimaryKeys: jest.fn().mockResolvedValue(mockPKs),
    }

    const schema = await getSchema(repository)
    expect(schema.tables.length).toBe(2)
    const sourceTable = schema.tables[0]
    const foreignTable = schema.tables[1]

    expect(sourceTable.columns[0].foreignKey).toBe(
      `${mockForeignTableName}.foreign_column`
    )
    expect(foreignTable.columns[0].isPrimaryKey).toBe(true)
  })

  it('sets custom types', async () => {
    const mockCustomTypes: CustomType[] = [
      { name: 'custom', internalName: '_custom', elements: ['el'] },
    ]
    const repository: Repository = {
      ...emptyRepository,
      selectCustomTypes: jest.fn().mockResolvedValue(mockCustomTypes),
    }

    const schema = await getSchema(repository)
    schema.customTypes.forEach((type, index) => {
      expect(type).toBe(mockCustomTypes[index])
    })
  })

  it('ignores custom types without elements', async () => {
    const mockCustomTypes: CustomType[] = [
      { name: 'custom', internalName: '_custom', elements: [] },
    ]
    const repository: Repository = {
      ...emptyRepository,
      selectCustomTypes: jest.fn().mockResolvedValue(mockCustomTypes),
    }

    const schema = await getSchema(repository)
    expect(schema.customTypes.length).toBe(0)
  })

  it('groups composite types', async () => {
    const mockCompositeTypeName = 'custom'
    const mockFirstCompositeType = {
      name: mockCompositeTypeName,
      columnName: 'column_1',
      dataType: 'int',
      position: 1,
      isRequired: true,
    }

    const mockSecondCompositeType = {
      name: mockCompositeTypeName,
      columnName: 'column_2',
      dataType: 'int',
      position: 2,
      isRequired: true,
    }

    const mockCompositeTypes: CompositeType[] = [
      mockFirstCompositeType,
      mockSecondCompositeType,
    ]
    const repository: Repository = {
      ...emptyRepository,
      selectCompositeTypes: jest.fn().mockResolvedValue(mockCompositeTypes),
    }

    const schema = await getSchema(repository)
    expect(schema.compositeTypes.length).toBe(1)

    const expectedStructure: CompositeTypeDescription[] = [
      {
        name: mockCompositeTypeName,
        fields: [
          {
            name: mockFirstCompositeType.columnName,
            dataType: mockFirstCompositeType.dataType,
            position: mockFirstCompositeType.position,
            isRequired: mockFirstCompositeType.isRequired,
          },
          {
            name: mockSecondCompositeType.columnName,
            dataType: mockSecondCompositeType.dataType,
            position: mockSecondCompositeType.position,
            isRequired: mockSecondCompositeType.isRequired,
          },
        ],
      },
    ]

    expect(schema.compositeTypes).toEqual(expectedStructure)
  })
})

================
File: src/get-schema.ts
================
import {
  Column,
  Table,
  ForeignKey,
  PrimaryKey,
  CustomType,
  View,
  Repository,
  CompositeType,
} from './repository'

export type ColumnDescription = Column & {
  isPrimaryKey: boolean
  foreignKey?: string
}

export type TableDescription = {
  name: string
  columns: ColumnDescription[]
}

export type CompositeTypeDescription = {
  name: string
  fields: {
    name: string
    dataType: string
    isRequired: boolean
    position: number
  }[]
}

export type Schema = {
  tables: TableDescription[]
  customTypes: CustomType[]
  compositeTypes: CompositeTypeDescription[]
  views: TableDescription[]
}

const getColumnsForTable = (table: Table, columns: Column[]) =>
  columns.filter((c) => c.table === table.name)

const withPrimaryKey = (
  source: Table | View,
  column: Column,
  primaryKeys: PrimaryKey[]
): Column & { isPrimaryKey: boolean } => {
  const isPrimaryKey = primaryKeys.find(
    (pk) => pk.table === source.name && pk.column === column.name
  )
  return { ...column, isPrimaryKey: !!isPrimaryKey }
}

const withForeignKey = (
  source: Table | View,
  column: Column & { isPrimaryKey: boolean },
  foreignKeys: ForeignKey[]
): Column & { foreignKey?: string; isPrimaryKey: boolean } => {
  const foreignKey = foreignKeys.find(
    (fk) => fk.sourceTable === source.name && fk.sourceColumn === column.name
  )

  if (!foreignKey) {
    return column
  }
  return {
    ...column,
    foreignKey: `${foreignKey.foreignTable}.${foreignKey.foreignColumn}`,
  }
}

const withColumns = (
  source: Table | View,
  columns: Column[],
  foreignKeys: ForeignKey[],
  primaryKeys: PrimaryKey[]
) => {
  const tableColumns = getColumnsForTable(source, columns)
  const withKeys = tableColumns.map((column) => {
    const withPks = withPrimaryKey(source, column, primaryKeys)
    const withFks = withForeignKey(source, withPks, foreignKeys)
    return withFks
  })
  return {
    name: source.name,
    columns: withKeys,
  }
}

export const getSchema = async (repository: Repository) => {
  const tables = await repository.selectTables()
  const views = await repository.selectViews()
  const columns = await repository.selectColumns()
  const foreignKeys = await repository.selectForeignKeys()
  const primaryKeys = await repository.selectPrimaryKeys()
  const customTypes = await repository.selectCustomTypes()
  const compositeTypes = await repository.selectCompositeTypes()

  const enrichedTables = tables.map((table) =>
    withColumns(table, columns, foreignKeys, primaryKeys)
  )

  const filteredCustomTypes = customTypes.filter(
    (custom) => custom.elements.filter((elem) => elem.length > 0).length > 0
  )

  const enrichedViews = views.map((view) =>
    withColumns(view, columns, foreignKeys, primaryKeys)
  )

  const compactedComposites = compactComposites(compositeTypes)

  return {
    tables: enrichedTables,
    customTypes: filteredCustomTypes,
    compositeTypes: compactedComposites,
    views: enrichedViews,
  }
}

const compactComposites = (compositeTypes: CompositeType[]) => {
  let map = new Map()
  compositeTypes.forEach((composite) => {
    let name: String = composite.name
    if (map.has(name)) {
      let elem = map.get(name)
      elem.fields.push({
        name: composite.columnName,
        dataType: composite.dataType,
        isRequired: composite.isRequired,
        position: composite.position,
      })
    } else {
      map.set(name, {
        name: name,
        fields: [
          {
            name: composite.columnName,
            dataType: composite.dataType,
            isRequired: composite.isRequired,
            position: composite.position,
          },
        ],
      })
    }
  })
  return [...map.values()]
}

================
File: src/index.ts
================
import { getSchema } from './get-schema'
import { createDatabase } from './database'
import { format } from './format'
import { createRepository } from './repository'
import { parseConfig } from './config'
import * as File from './file'

export const generateDocumentation = async (
  configPath: string,
  outputPath: string
) => {
  const config = parseConfig(await File.read(configPath))
  const database = await createDatabase(config)
  const repository = createRepository(database.query)
  try {
    const schema = await getSchema(repository)
    await File.write(outputPath, format(schema))
  } catch (e) {
    throw e
  } finally {
    await database.disconnect()
  }
}

================
File: src/postgre-data-types.json
================
{
  "smallint": "https://www.postgresql.org/docs/9.5/datatype-numeric.html",
  "integer": "https://www.postgresql.org/docs/9.5/datatype-numeric.html",
  "bigint": "https://www.postgresql.org/docs/9.5/datatype-numeric.html",
  "decimal": "https://www.postgresql.org/docs/9.5/datatype-numeric.html",
  "numeric": "https://www.postgresql.org/docs/9.5/datatype-numeric.html",
  "real": "https://www.postgresql.org/docs/9.5/datatype-numeric.html",
  "double precision": "https://www.postgresql.org/docs/9.5/datatype-numeric.html",
  "smallserial": "https://www.postgresql.org/docs/9.5/datatype-numeric.html",
  "serial": "https://www.postgresql.org/docs/9.5/datatype-numeric.html",
  "bigserial": "https://www.postgresql.org/docs/9.5/datatype-numeric.html",
  "money": "https://www.postgresql.org/docs/9.5/datatype-money.html",
  "character": "https://www.postgresql.org/docs/9.5/datatype-character.html",
  "char": "https://www.postgresql.org/docs/9.5/datatype-character.html",
  "varchar": "https://www.postgresql.org/docs/9.5/datatype-character.html",
  "varyingchar": "https://www.postgresql.org/docs/9.5/datatype-character.html",
  "character varying": "https://www.postgresql.org/docs/9.5/datatype-character.html",
  "text": "https://www.postgresql.org/docs/9.5/datatype-character.html",
  "bytea": "https://www.postgresql.org/docs/9.5/datatype-binary.html",
  "timestamp": "https://www.postgresql.org/docs/9.5/datatype-datetime.html",
  "date": "https://www.postgresql.org/docs/9.5/datatype-datetime.html",
  "time": "https://www.postgresql.org/docs/9.5/datatype-datetime.html",
  "time without time zone": "https://www.postgresql.org/docs/9.5/datatype-datetime.html",
  "time with time zone": "https://www.postgresql.org/docs/9.5/datatype-datetime.html",
  "timestamp without time zone": "https://www.postgresql.org/docs/9.5/datatype-datetime.html",
  "timestamp with time zone": "https://www.postgresql.org/docs/9.5/datatype-datetime.html",
  "interval": "https://www.postgresql.org/docs/9.5/datatype-datetime.html",
  "boolean": "https://www.postgresql.org/docs/9.5/datatype-boolean.html",
  "point": "https://www.postgresql.org/docs/9.5/datatype-geometric.html",
  "line": "https://www.postgresql.org/docs/9.5/datatype-geometric.html",
  "lseg": "https://www.postgresql.org/docs/9.5/datatype-geometric.html",
  "box": "https://www.postgresql.org/docs/9.5/datatype-geometric.html",
  "path": "https://www.postgresql.org/docs/9.5/datatype-geometric.html",
  "polygon": "https://www.postgresql.org/docs/9.5/datatype-geometric.html",
  "circle": "https://www.postgresql.org/docs/9.5/datatype-geometric.html",
  "cidr": "https://www.postgresql.org/docs/9.5/datatype-net-types.html",
  "inet": "https://www.postgresql.org/docs/9.5/datatype-net-types.html",
  "macaddr": "https://www.postgresql.org/docs/9.5/datatype-net-types.html",
  "oidoid": "https://www.postgresql.org/docs/9.5/datatype-oid.html",
  "regproc": "https://www.postgresql.org/docs/9.5/datatype-oid.html",
  "regprocedure": "https://www.postgresql.org/docs/9.5/datatype-oid.html",
  "regoper": "https://www.postgresql.org/docs/9.5/datatype-oid.html",
  "regoperator": "https://www.postgresql.org/docs/9.5/datatype-oid.html",
  "regclass": "https://www.postgresql.org/docs/9.5/datatype-oid.html",
  "regtype": "https://www.postgresql.org/docs/9.5/datatype-oid.html",
  "regrole": "https://www.postgresql.org/docs/9.5/datatype-oid.html",
  "regnamespace": "https://www.postgresql.org/docs/9.5/datatype-oid.html",
  "regconfig": "https://www.postgresql.org/docs/9.5/datatype-oid.html",
  "regdictionary": "https://www.postgresql.org/docs/9.5/datatype-oid.html",
  "any": "https://www.postgresql.org/docs/9.5/datatype-pseudo.html",
  "anyelement": "https://www.postgresql.org/docs/9.5/datatype-pseudo.html",
  "anyarray": "https://www.postgresql.org/docs/9.5/datatype-pseudo.html",
  "anynonarray": "https://www.postgresql.org/docs/9.5/datatype-pseudo.html",
  "anyenum": "https://www.postgresql.org/docs/9.5/datatype-pseudo.html",
  "anyrange": "https://www.postgresql.org/docs/9.5/datatype-pseudo.html",
  "cstring": "https://www.postgresql.org/docs/9.5/datatype-pseudo.html",
  "internal": "https://www.postgresql.org/docs/9.5/datatype-pseudo.html",
  "language_handler": "https://www.postgresql.org/docs/9.5/datatype-pseudo.html",
  "fdw_handler": "https://www.postgresql.org/docs/9.5/datatype-pseudo.html",
  "tsm_handler": "https://www.postgresql.org/docs/9.5/datatype-pseudo.html",
  "record": "https://www.postgresql.org/docs/9.5/datatype-pseudo.html",
  "trigger": "https://www.postgresql.org/docs/9.5/datatype-pseudo.html",
  "event_trigger": "https://www.postgresql.org/docs/9.5/datatype-pseudo.html",
  "pg_ddl_command": "https://www.postgresql.org/docs/9.5/datatype-pseudo.html",
  "void": "https://www.postgresql.org/docs/9.5/datatype-pseudo.html",
  "opaque": "https://www.postgresql.org/docs/9.5/datatype-pseudo.html",
  "uuid": "https://www.postgresql.org/docs/9.1/datatype-uuid.html",
  "jsonb": "https://www.postgresql.org/docs/9.4/datatype-json.html"
}

================
File: src/repository.ts
================
import { Database } from './database'
import { Decoder } from 'elm-decoders'

export type Table = {
  name: string
}

const tableResultDecoder: Decoder<Table[]> = Decoder.array(
  Decoder.object({
    tablename: Decoder.string,
  }).map((res) => ({
    name: res.tablename,
  }))
)

export type Column = {
  table: string
  name: string
  default?: string
  isNullable: boolean
  dataType: string
}

const columnResultDecoder: Decoder<Column[]> = Decoder.array(
  Decoder.object({
    table_name: Decoder.string,
    column_name: Decoder.string,
    column_default: Decoder.optional(Decoder.string),
    is_nullable: Decoder.string.map((s) => s === 'YES'),
    data_type: Decoder.string,
    udt_name: Decoder.string,
    character_maximum_length: Decoder.optional(Decoder.number)
  }).map((res) => {
    return {
      table: res.table_name,
      name: res.column_name,
      default: res.column_default,
      isNullable: res.is_nullable,
      dataType: get_datatype(res)
    }
  })
)

const get_datatype = (res: {udt_name: string, data_type: string, character_maximum_length: number | undefined}) => {
  if (res.data_type == 'USER-DEFINED') {
    return res.udt_name
  }
  if (res.data_type == 'character' && res.character_maximum_length) {
    return `character (${res.character_maximum_length})`
  }
  return res.data_type
}

export type View = {
  name: string
}

const viewResultDecoder: Decoder<View[]> = Decoder.array(
  Decoder.object({
    table_name: Decoder.string,
  }).map((res) => ({
    name: res.table_name,
  }))
)

export type ForeignKey = {
  constraintName: string
  sourceTable: string
  sourceColumn: string
  foreignTable: string
  foreignColumn: string
}

const foreignKeyResultDecoder: Decoder<ForeignKey[]> = Decoder.array(
  Decoder.object({
    constraint_name: Decoder.string,
    source_table: Decoder.string,
    source_column: Decoder.string,
    foreign_table: Decoder.string,
    foreign_column: Decoder.string,
  }).map((res) => ({
    constraintName: res.constraint_name,
    sourceTable: res.source_table,
    sourceColumn: res.source_column,
    foreignTable: res.foreign_table,
    foreignColumn: res.foreign_column,
  }))
)

export type PrimaryKey = {
  constraintName: string
  table: string
  column: string
}

const primaryKeyResultDecoder: Decoder<PrimaryKey[]> = Decoder.array(
  Decoder.object({
    constraint_name: Decoder.string,
    table_name: Decoder.string,
    column_name: Decoder.string,
  }).map((res) => ({
    constraintName: res.constraint_name,
    table: res.table_name,
    column: res.column_name,
  }))
)

export type CustomType = {
  name: string
  internalName: string
  elements: string[]
}

const customTypeResultDecoder: Decoder<CustomType[]> = Decoder.array(
  Decoder.object({
    name: Decoder.string,
    internal_name: Decoder.string,
    elements: Decoder.string.map((str) => str.split(',')),
  }).map((res) => ({
    name: res.name,
    internalName: res.internal_name,
    elements: res.elements,
  }))
)

export type CompositeType = {
  name: string,
  columnName: string,
  dataType: string,
  position: number,
  isRequired: boolean
}

const compositeTypeResultDecoder: Decoder<CompositeType[]> = Decoder.array(
  Decoder.object({
    obj_name: Decoder.string,
    column_name: Decoder.string,
    data_type: Decoder.string,
    ordinal_position: Decoder.number,
    is_required: Decoder.boolean
  }).map((res) => ({
    name: res.obj_name,
    columnName: res.column_name,
    dataType: res.data_type,
    position: res.ordinal_position,
    isRequired: res.is_required
  }))
)

export const createRepository = (query: Database['query']) => {
  const selectTables = async () => {
    const queryString = `SELECT * FROM pg_catalog.pg_tables WHERE tablename NOT LIKE 'sql_%' AND tablename NOT LIKE 'pg_%'`
    const result = await query(queryString)
    const decoded = tableResultDecoder.guard(result.rows)
    return decoded
  }
  const selectColumns = async () => {
    const queryString = `SELECT * FROM information_schema."columns" ORDER BY ordinal_position`
    const result = await query(queryString)
    const decoded = columnResultDecoder.guard(result.rows)
    return decoded
  }

  const selectViews = async () => {
    const queryString = `SELECT table_name FROM INFORMATION_SCHEMA.views WHERE table_schema = ANY (current_schemas(false))`
    const result = await query(queryString)
    const decoded = viewResultDecoder.guard(result.rows)
    return decoded
  }

  const selectForeignKeys = async () => {
    const queryString = `
      SELECT
        tc.table_schema,
        tc.constraint_name,
        tc.table_name as source_table,
        kcu.column_name as source_column,
        ccu.table_name AS foreign_table,
        ccu.column_name AS foreign_column
      FROM  information_schema.table_constraints AS tc
      JOIN information_schema.key_column_usage AS kcu
        ON tc.constraint_name = kcu.constraint_name
        AND tc.table_schema = kcu.table_schema
      JOIN information_schema.constraint_column_usage AS ccu
        ON ccu.constraint_name = tc.constraint_name
        AND ccu.table_schema = tc.table_schema
      WHERE tc.constraint_type = 'FOREIGN KEY'
    `
    const result = await query(queryString)
    const decoded = foreignKeyResultDecoder.guard(result.rows)
    return decoded
  }
  const selectPrimaryKeys = async () => {
    const queryString = `
      SELECT kcu.table_schema,
        kcu.table_name,
        tco.constraint_name,
        kcu.column_name AS column_name
      FROM information_schema.table_constraints tco
      JOIN information_schema.key_column_usage kcu
        ON kcu.constraint_name = tco.constraint_name
        AND kcu.constraint_schema = tco.constraint_schema
        AND kcu.constraint_name = tco.constraint_name
      WHERE tco.constraint_type = 'PRIMARY KEY'
    `
    const result = await query(queryString)
    const decoded = primaryKeyResultDecoder.guard(result.rows)
    return decoded
  }
  const selectCustomTypes = async () => {
    const queryString = `
      SELECT n.nspname AS schema,
          pg_catalog.format_type ( t.oid, NULL ) AS name,
          t.typname AS internal_name,
          pg_catalog.array_to_string (
              ARRAY( SELECT e.enumlabel
                      FROM pg_catalog.pg_enum e
                      WHERE e.enumtypid = t.oid
                      ORDER BY e.oid ), E', '
              ) AS elements,
          pg_catalog.obj_description ( t.oid, 'pg_type' ) AS description
      FROM pg_catalog.pg_type t
      LEFT JOIN pg_catalog.pg_namespace n
          ON n.oid = t.typnamespace
      WHERE ( t.typrelid = 0
              OR ( SELECT c.relkind = 'c'
                      FROM pg_catalog.pg_class c
                      WHERE c.oid = t.typrelid
                  )
          )
          AND NOT EXISTS
              ( SELECT 1
                  FROM pg_catalog.pg_type el
                  WHERE el.oid = t.typelem
                      AND el.typarray = t.oid
              )
          AND n.nspname <> 'pg_catalog'
          AND n.nspname <> 'information_schema'
          AND pg_catalog.pg_type_is_visible ( t.oid )
      ORDER BY 1, 2;
    `

    const result = await query(queryString)
    const decoded = customTypeResultDecoder.guard(result.rows)
    return decoded
  }

  const selectCompositeTypes = async () => {
    const queryString = `
      WITH types AS (
        SELECT n.nspname,
            pg_catalog.format_type ( t.oid, NULL ) AS obj_name,
            CASE
                WHEN t.typrelid != 0 THEN CAST ( 'tuple' AS pg_catalog.text )
                WHEN t.typlen < 0 THEN CAST ( 'var' AS pg_catalog.text )
                ELSE CAST ( t.typlen AS pg_catalog.text )
                END AS obj_type,
            coalesce ( pg_catalog.obj_description ( t.oid, 'pg_type' ), '' ) AS description
        FROM pg_catalog.pg_type t
        JOIN pg_catalog.pg_namespace n
            ON n.oid = t.typnamespace
        WHERE ( t.typrelid = 0
                OR ( SELECT c.relkind = 'c'
                        FROM pg_catalog.pg_class c
                        WHERE c.oid = t.typrelid ) )
            AND NOT EXISTS (
                    SELECT 1
                        FROM pg_catalog.pg_type el
                        WHERE el.oid = t.typelem
                        AND el.typarray = t.oid )
            AND n.nspname <> 'pg_catalog'
            AND n.nspname <> 'information_schema'
            AND n.nspname !~ '^pg_toast'
      ),
      cols AS (
          SELECT n.nspname::text AS schema_name,
                  pg_catalog.format_type ( t.oid, NULL ) AS obj_name,
                  a.attname::text AS column_name,
                  pg_catalog.format_type ( a.atttypid, a.atttypmod ) AS data_type,
                  a.attnotnull AS is_required,
                  a.attnum AS ordinal_position,
                  pg_catalog.col_description ( a.attrelid, a.attnum ) AS description
              FROM pg_catalog.pg_attribute a
              JOIN pg_catalog.pg_type t
                  ON a.attrelid = t.typrelid
              JOIN pg_catalog.pg_namespace n
                  ON ( n.oid = t.typnamespace )
              JOIN types
                  ON ( types.nspname = n.nspname
                      AND types.obj_name = pg_catalog.format_type ( t.oid, NULL ) )
              WHERE a.attnum > 0
                  AND NOT a.attisdropped
      )
      SELECT  cols.obj_name,
              cols.column_name,
              cols.data_type,
              cols.ordinal_position,
              cols.is_required,
              coalesce ( cols.description, '' ) AS description
          FROM cols
          ORDER BY cols.obj_name,
                  cols.ordinal_position ;
          `
    const result = await query(queryString)
    const decoded = compositeTypeResultDecoder.guard(result.rows)
    return decoded
  }

  return {
    selectTables,
    selectColumns,
    selectViews,
    selectForeignKeys,
    selectPrimaryKeys,
    selectCustomTypes,
    selectCompositeTypes,
  }
}

export type Repository = ReturnType<typeof createRepository>

================
File: tsconfig.json
================
{
  "compilerOptions": {
    "allowJs": true,
    "esModuleInterop": true,
    "module": "commonjs",
    "moduleResolution": "node",
    "target": "es2019",
    "outDir": "dist",
    "sourceMap": true,
    "strict": true,
    "resolveJsonModule": true
  },
  "include": ["src/**/*.ts"],
}
